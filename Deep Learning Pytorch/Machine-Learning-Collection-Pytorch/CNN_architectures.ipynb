{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_architectures\n",
    "\n",
    "\n",
    "https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Pytorch/CNN_architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1000])\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "From scratch implementation of the famous ResNet models.\n",
    "The intuition for ResNet is simple and clear, but to code\n",
    "it didn't feel super clear at first, even when reading Pytorch own\n",
    "implementation. \n",
    "\n",
    "Programmed by Aladdin Persson <aladdin.persson at hotmail dot com>\n",
    "*    2020-04-12 Initial coding\n",
    "*    2022-12-20 Update comments, code revision, checked still works with latest PyTorch version\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class block(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, intermediate_channels, identity_downsample=None, stride=1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels,\n",
    "            intermediate_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            intermediate_channels,\n",
    "            intermediate_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            intermediate_channels,\n",
    "            intermediate_channels * self.expansion,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, image_channels, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Essentially the entire ResNet architecture are in these 4 lines below\n",
    "        self.layer1 = self._make_layer(\n",
    "            block, layers[0], intermediate_channels=64, stride=1\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block, layers[1], intermediate_channels=128, stride=2\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block, layers[2], intermediate_channels=256, stride=2\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block, layers[3], intermediate_channels=512, stride=2\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * 4, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n",
    "        # we need to adapt the Identity (skip connection) so it will be able to be added\n",
    "        # to the layer that's ahead\n",
    "        if stride != 1 or self.in_channels != intermediate_channels * 4:\n",
    "            identity_downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    self.in_channels,\n",
    "                    intermediate_channels * 4,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False,\n",
    "                ),\n",
    "                nn.BatchNorm2d(intermediate_channels * 4),\n",
    "            )\n",
    "\n",
    "        layers.append(\n",
    "            block(self.in_channels, intermediate_channels, identity_downsample, stride)\n",
    "        )\n",
    "\n",
    "        # The expansion size is always 4 for ResNet 50,101,152\n",
    "        self.in_channels = intermediate_channels * 4\n",
    "\n",
    "        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
    "        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n",
    "        # and also same amount of channels.\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(block(self.in_channels, intermediate_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def ResNet50(img_channel=3, num_classes=1000):\n",
    "    return ResNet(block, [3, 4, 6, 3], img_channel, num_classes)\n",
    "\n",
    "\n",
    "def ResNet101(img_channel=3, num_classes=1000):\n",
    "    return ResNet(block, [3, 4, 23, 3], img_channel, num_classes)\n",
    "\n",
    "\n",
    "def ResNet152(img_channel=3, num_classes=1000):\n",
    "    return ResNet(block, [3, 8, 36, 3], img_channel, num_classes)\n",
    "\n",
    "\n",
    "def test():\n",
    "    BATCH_SIZE = 4\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net = ResNet101(img_channel=3, num_classes=1000).to(device)\n",
    "    y = net(torch.randn(BATCH_SIZE, 3, 224, 224)).to(device)\n",
    "    assert y.size() == torch.Size([BATCH_SIZE, 1000])\n",
    "    print(y.size())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch_efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "An implementation of EfficientNet CNN architecture.\n",
    "\n",
    "Programmed by Aladdin Persson <aladdin.persson at hotmail dot com>\n",
    "*    2021-02-05 Initial coding\n",
    "*    2022-12-20 Update comments, code revision, checked still works with latest PyTorch version\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from math import ceil\n",
    "\n",
    "base_model = [\n",
    "    # expand_ratio, channels, repeats, stride, kernel_size\n",
    "    [1, 16, 1, 1, 3],\n",
    "    [6, 24, 2, 2, 3],\n",
    "    [6, 40, 2, 2, 5],\n",
    "    [6, 80, 3, 2, 3],\n",
    "    [6, 112, 3, 1, 5],\n",
    "    [6, 192, 4, 2, 5],\n",
    "    [6, 320, 1, 1, 3],\n",
    "]\n",
    "\n",
    "phi_values = {\n",
    "    # tuple of: (phi_value, resolution, drop_rate)\n",
    "    \"b0\": (0, 224, 0.2),  # alpha, beta, gamma, depth = alpha ** phi\n",
    "    \"b1\": (0.5, 240, 0.2),\n",
    "    \"b2\": (1, 260, 0.3),\n",
    "    \"b3\": (2, 300, 0.3),\n",
    "    \"b4\": (3, 380, 0.4),\n",
    "    \"b5\": (4, 456, 0.4),\n",
    "    \"b6\": (5, 528, 0.5),\n",
    "    \"b7\": (6, 600, 0.5),\n",
    "}\n",
    "\n",
    "\n",
    "class CNNBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, kernel_size, stride, padding, groups=1\n",
    "    ):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.cnn = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride,\n",
    "            padding,\n",
    "            groups=groups,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.silu = nn.SiLU()  # SiLU <-> Swish\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.silu(self.bn(self.cnn(x)))\n",
    "\n",
    "\n",
    "class SqueezeExcitation(nn.Module):\n",
    "    def __init__(self, in_channels, reduced_dim):\n",
    "        super(SqueezeExcitation, self).__init__()\n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),  # C x H x W -> C x 1 x 1\n",
    "            nn.Conv2d(in_channels, reduced_dim, 1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(reduced_dim, in_channels, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.se(x)\n",
    "\n",
    "\n",
    "class InvertedResidualBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        padding,\n",
    "        expand_ratio,\n",
    "        reduction=4,  # squeeze excitation\n",
    "        survival_prob=0.8,  # for stochastic depth\n",
    "    ):\n",
    "        super(InvertedResidualBlock, self).__init__()\n",
    "        self.survival_prob = 0.8\n",
    "        self.use_residual = in_channels == out_channels and stride == 1\n",
    "        hidden_dim = in_channels * expand_ratio\n",
    "        self.expand = in_channels != hidden_dim\n",
    "        reduced_dim = int(in_channels / reduction)\n",
    "\n",
    "        if self.expand:\n",
    "            self.expand_conv = CNNBlock(\n",
    "                in_channels,\n",
    "                hidden_dim,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            )\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            CNNBlock(\n",
    "                hidden_dim,\n",
    "                hidden_dim,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                groups=hidden_dim,\n",
    "            ),\n",
    "            SqueezeExcitation(hidden_dim, reduced_dim),\n",
    "            nn.Conv2d(hidden_dim, out_channels, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "    def stochastic_depth(self, x):\n",
    "        if not self.training:\n",
    "            return x\n",
    "\n",
    "        binary_tensor = (\n",
    "            torch.rand(x.shape[0], 1, 1, 1, device=x.device) < self.survival_prob\n",
    "        )\n",
    "        return torch.div(x, self.survival_prob) * binary_tensor\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.expand_conv(inputs) if self.expand else inputs\n",
    "\n",
    "        if self.use_residual:\n",
    "            return self.stochastic_depth(self.conv(x)) + inputs\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self, version, num_classes):\n",
    "        super(EfficientNet, self).__init__()\n",
    "        width_factor, depth_factor, dropout_rate = self.calculate_factors(version)\n",
    "        last_channels = ceil(1280 * width_factor)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.features = self.create_features(width_factor, depth_factor, last_channels)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(last_channels, num_classes),\n",
    "        )\n",
    "\n",
    "    def calculate_factors(self, version, alpha=1.2, beta=1.1):\n",
    "        phi, res, drop_rate = phi_values[version]\n",
    "        depth_factor = alpha**phi\n",
    "        width_factor = beta**phi\n",
    "        return width_factor, depth_factor, drop_rate\n",
    "\n",
    "    def create_features(self, width_factor, depth_factor, last_channels):\n",
    "        channels = int(32 * width_factor)\n",
    "        features = [CNNBlock(3, channels, 3, stride=2, padding=1)]\n",
    "        in_channels = channels\n",
    "\n",
    "        for expand_ratio, channels, repeats, stride, kernel_size in base_model:\n",
    "            out_channels = 4 * ceil(int(channels * width_factor) / 4)\n",
    "            layers_repeats = ceil(repeats * depth_factor)\n",
    "\n",
    "            for layer in range(layers_repeats):\n",
    "                features.append(\n",
    "                    InvertedResidualBlock(\n",
    "                        in_channels,\n",
    "                        out_channels,\n",
    "                        expand_ratio=expand_ratio,\n",
    "                        stride=stride if layer == 0 else 1,\n",
    "                        kernel_size=kernel_size,\n",
    "                        padding=kernel_size // 2,  # if k=1:pad=0, k=3:pad=1, k=5:pad=2\n",
    "                    )\n",
    "                )\n",
    "                in_channels = out_channels\n",
    "\n",
    "        features.append(\n",
    "            CNNBlock(in_channels, last_channels, kernel_size=1, stride=1, padding=0)\n",
    "        )\n",
    "\n",
    "        return nn.Sequential(*features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.features(x))\n",
    "        return self.classifier(x.view(x.shape[0], -1))\n",
    "\n",
    "\n",
    "def test():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    version = \"b0\"\n",
    "    phi, res, drop_rate = phi_values[version]\n",
    "    num_examples, num_classes = 4, 10\n",
    "    x = torch.randn((num_examples, 3, res, res)).to(device)\n",
    "    model = EfficientNet(\n",
    "        version=version,\n",
    "        num_classes=num_classes,\n",
    "    ).to(device)\n",
    "\n",
    "    print(model(x).shape)  # (num_examples, num_classes)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
